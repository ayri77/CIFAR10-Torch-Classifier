{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Kaggle Submission Evaluation\n",
    "\n",
    "This notebook loads a trained CIFAR-10 classification model and generates predictions on the official Kaggle test set.\n",
    "The output is a `submission.csv` file compatible with the competition format.\n",
    "\n",
    "## Workflow:\n",
    "1. Select a trained model by name\n",
    "2. Load model configuration and weights\n",
    "3. Prepare the Kaggle test dataset\n",
    "4. Run inference and collect predictions\n",
    "5. Export submission file for Kaggle upload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Select Model to Evaluate\n",
    "Set the name of the trained model you want to evaluate on the Kaggle test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the trained model you want to use for generating Kaggle submission\n",
    "model_name = \"densenet121\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìÅ Set up paths and project structure, import libraries\n",
    "\n",
    "Add the root directory to `sys.path` and import key folder constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from utils.paths import MODELS_DIR, DATA_DIR\n",
    "\n",
    "# CIFAR10-Torch-Classifier and config.py\n",
    "from core.cifar10_classifier import CIFAR10Classifier\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ Load the trained model\n",
    "\n",
    "Load the model and its configuration from the specified `model_name`.  \n",
    "Also extract the dataset mean and standard deviation used for normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pbori\\Documents\\ML AI Courses\\Homework\\CIFAR10_Torch_Classifier\\core\\cifar10_classifier.py:624: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location=self.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "CIFAR10_DenseNet121                           [1, 10]                   --\n",
       "‚îú‚îÄDenseNet: 1-1                               [1, 10]                   --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-1                        [1, 1024, 4, 4]           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       [1, 64, 32, 32]           1,728\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-2                  [1, 64, 32, 32]           128\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-3                         [1, 64, 32, 32]           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-4                     [1, 64, 32, 32]           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄ_DenseBlock: 3-5                  [1, 256, 32, 32]          335,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄ_Transition: 3-6                  [1, 128, 16, 16]          33,280\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄ_DenseBlock: 3-7                  [1, 512, 16, 16]          919,680\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄ_Transition: 3-8                  [1, 256, 8, 8]            132,096\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄ_DenseBlock: 3-9                  [1, 1024, 8, 8]           2,837,760\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄ_Transition: 3-10                 [1, 512, 4, 4]            526,336\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄ_DenseBlock: 3-11                 [1, 1024, 4, 4]           2,158,080\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-12                 [1, 1024, 4, 4]           2,048\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-2                            [1, 10]                   10,250\n",
       "===============================================================================================\n",
       "Total params: 6,956,426\n",
       "Trainable params: 6,956,426\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 888.43\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 55.80\n",
       "Params size (MB): 27.83\n",
       "Estimated Total Size (MB): 83.64\n",
       "==============================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_path = os.path.join(MODELS_DIR, model_name,  f\"{model_name}_config.json\")\n",
    "model_path = os.path.join(MODELS_DIR, model_name,  f\"{model_name}_best_model.pth\")\n",
    "\n",
    "assert os.path.exists(config_path), f\"Config not found at {config_path}\"\n",
    "assert os.path.exists(model_path), f\"Model not found at {model_path}\"\n",
    "\n",
    "model = CIFAR10Classifier.load_model(\n",
    "    model_name=model_name,\n",
    "    config_path=config_path,\n",
    "    model_path=model_path\n",
    ")\n",
    "\n",
    "display(model.summary())\n",
    "mean, std = torch.tensor(model.mean), torch.tensor(model.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßæ Define Kaggle test dataset\n",
    "\n",
    "This custom dataset class is used to load and preprocess test images  \n",
    "from the Kaggle competition directory. Images are sorted by filename ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaggleCIFAR10Dataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = sorted([\n",
    "            os.path.join(image_dir, fname)\n",
    "            for fname in os.listdir(image_dir)\n",
    "            if fname.endswith(\".png\")\n",
    "        ], key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, os.path.basename(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üåÄ Define image transformations\n",
    "\n",
    "Define the transformation pipeline used to preprocess the Kaggle test images  \n",
    "to match the input format expected by the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì§ Generate Kaggle submission\n",
    "\n",
    "This function runs the model on the Kaggle test dataset and saves the predictions  \n",
    "as a `submission.csv` file in the correct format: `[Id, Label]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_kaggle_submission(model, dataloader, class_names, output_path=\"submission.csv\", device=\"cuda\"):\n",
    "    model.model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in tqdm(dataloader, desc=\"üì§ Generating predictions\", unit=\"batch\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model.model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            for img_path, label in zip(image_ids, predicted.cpu().numpy()):\n",
    "                img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "                predictions.append((int(img_id), class_names[label]))\n",
    "\n",
    "    df = pd.DataFrame(predictions, columns=[\"Id\", \"Label\"])\n",
    "    df.to_csv(output_path, index=False, sep=\",\")\n",
    "    print(f\"\\n‚úÖ Saved submission to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöÄ Run Inference and Save Results\n",
    "\n",
    "Load the Kaggle test dataset, run the model to generate predictions,  \n",
    "and save the result as a CSV file compatible with Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì§ Generating predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2344/2344 [28:38<00:00,  1.36batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved submission to c:\\Users\\pbori\\Documents\\ML AI Courses\\Homework\\CIFAR10_Torch_Classifier\\data\\Kaggle\\submission_densenet121.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset and loader\n",
    "image_path = os.path.join(DATA_DIR, \"Kaggle\", \"test\")\n",
    "dataset = KaggleCIFAR10Dataset(\n",
    "    image_dir=image_path,\n",
    "    transform=kaggle_transform\n",
    ")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# generate predictions\n",
    "class_path = os.path.join(DATA_DIR, \"class_names.json\")\n",
    "with open(class_path, \"r\") as f:\n",
    "    class_names = json.load(f)\n",
    "    \n",
    "output_path = os.path.join(DATA_DIR, \"Kaggle\", \"submission_densenet121.csv\")\n",
    "generate_kaggle_submission(model, loader, class_names, output_path=output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
