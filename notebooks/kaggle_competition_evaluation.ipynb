{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Kaggle Submission Evaluation\n",
    "\n",
    "This notebook loads a trained CIFAR-10 classification model and generates predictions on the official Kaggle test set.\n",
    "The output is a `submission.csv` file compatible with the competition format.\n",
    "\n",
    "## Workflow:\n",
    "1. Select a trained model by name\n",
    "2. Load model configuration and weights\n",
    "3. Prepare the Kaggle test dataset\n",
    "4. Run inference and collect predictions\n",
    "5. Export submission file for Kaggle upload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Select Model to Evaluate\n",
    "Set the name of the trained model you want to evaluate on the Kaggle test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the trained model you want to use for generating Kaggle submission\n",
    "model_name = \"cnn_mixup_cutout_SGD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìÅ Set up paths and project structure, import libraries\n",
    "\n",
    "Add the root directory to `sys.path` and import key folder constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from utils.paths import MODELS_DIR, DATA_DIR\n",
    "\n",
    "# CIFAR10-Torch-Classifier and config.py\n",
    "from core.cifar10_classifier import CIFAR10Classifier\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ Load the trained model\n",
    "\n",
    "Load the model and its configuration from the specified `model_name`.  \n",
    "Also extract the dataset mean and standard deviation used for normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CIFAR10_CNN                              [1, 10]                   --\n",
       "‚îú‚îÄSequential: 1-1                        [1, 256, 2, 2]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-1                       [1, 32, 32, 32]           896\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                  [1, 32, 32, 32]           64\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-3                         [1, 32, 32, 32]           --\n",
       "‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                    [1, 32, 16, 16]           --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-5                       [1, 64, 16, 16]           18,496\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                  [1, 64, 16, 16]           128\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-7                         [1, 64, 16, 16]           --\n",
       "‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                    [1, 64, 8, 8]             --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-9                       [1, 128, 8, 8]            73,856\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                 [1, 128, 8, 8]            256\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-11                        [1, 128, 8, 8]            --\n",
       "‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                   [1, 128, 4, 4]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-13                      [1, 256, 4, 4]            295,168\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                 [1, 256, 4, 4]            512\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-15                        [1, 256, 4, 4]            --\n",
       "‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                   [1, 256, 2, 2]            --\n",
       "‚îú‚îÄSequential: 1-2                        [1, 10]                   --\n",
       "‚îÇ    ‚îî‚îÄFlatten: 2-17                     [1, 1024]                 --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-18                      [1, 512]                  524,800\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-19                      [1, 256]                  131,328\n",
       "‚îÇ    ‚îî‚îÄBatchNorm1d: 2-20                 [1, 256]                  512\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-21                        [1, 256]                  --\n",
       "‚îÇ    ‚îî‚îÄDropout: 2-22                     [1, 256]                  --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-23                      [1, 10]                   2,570\n",
       "==========================================================================================\n",
       "Total params: 1,048,586\n",
       "Trainable params: 1,048,586\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 15.76\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.99\n",
       "Params size (MB): 4.19\n",
       "Estimated Total Size (MB): 5.20\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_path = os.path.join(MODELS_DIR, model_name,  f\"{model_name}_config.json\")\n",
    "model_path = os.path.join(MODELS_DIR, model_name,  f\"{model_name}_best_model.pth\")\n",
    "\n",
    "assert os.path.exists(config_path), f\"Config not found at {config_path}\"\n",
    "assert os.path.exists(model_path), f\"Model not found at {model_path}\"\n",
    "\n",
    "model = CIFAR10Classifier.load_model(\n",
    "    model_name=model_name,\n",
    "    config_path=config_path,\n",
    "    model_path=model_path\n",
    ")\n",
    "\n",
    "display(model.summary())\n",
    "mean, std = torch.tensor(model.mean), torch.tensor(model.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßæ Define Kaggle test dataset\n",
    "\n",
    "This custom dataset class is used to load and preprocess test images  \n",
    "from the Kaggle competition directory. Images are sorted by filename ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaggleCIFAR10Dataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = sorted([\n",
    "            os.path.join(image_dir, fname)\n",
    "            for fname in os.listdir(image_dir)\n",
    "            if fname.endswith(\".png\")\n",
    "        ], key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, os.path.basename(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üåÄ Define image transformations\n",
    "\n",
    "Define the transformation pipeline used to preprocess the Kaggle test images  \n",
    "to match the input format expected by the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì§ Generate Kaggle submission\n",
    "\n",
    "This function runs the model on the Kaggle test dataset and saves the predictions  \n",
    "as a `submission.csv` file in the correct format: `[Id, Label]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_kaggle_submission(model, dataloader, class_names, output_path=\"submission.csv\", device=\"cuda\"):\n",
    "    model.model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in tqdm(dataloader, desc=\"üì§ Generating predictions\", unit=\"batch\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model.model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            for img_path, label in zip(image_ids, predicted.cpu().numpy()):\n",
    "                img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "                predictions.append((int(img_id), class_names[label]))\n",
    "\n",
    "    df = pd.DataFrame(predictions, columns=[\"Id\", \"Label\"])\n",
    "    df.to_csv(output_path, index=False, sep=\",\")\n",
    "    print(f\"\\n‚úÖ Saved submission to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöÄ Run Inference and Save Results\n",
    "\n",
    "Load the Kaggle test dataset, run the model to generate predictions,  \n",
    "and save the result as a CSV file compatible with Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì§ Generating predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2344/2344 [42:59<00:00,  1.10s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved submission to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset and loader\n",
    "image_path = os.path.join(DATA_DIR, \"Kaggle\", \"test\")\n",
    "dataset = KaggleCIFAR10Dataset(\n",
    "    image_dir=image_path,\n",
    "    transform=kaggle_transform\n",
    ")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# generate predictions\n",
    "class_path = os.path.join(DATA_DIR, \"class_names.json\")\n",
    "with open(class_path, \"r\") as f:\n",
    "    class_names = json.load(f)\n",
    "    \n",
    "output_path = os.path.join(DATA_DIR, \"Kaggle\", \"submission.csv\")\n",
    "generate_kaggle_submission(model, loader, class_names, output_path=output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
